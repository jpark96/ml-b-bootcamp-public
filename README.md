# ML@B BOOTCAMP MATERIAL 

This is where all Machine Learning at Berkeley's Bootcamp material is housed. Feel free to use for pedagogical purposes!

Slides are available in "presentation/" folder.

Table of Contents 
====

1. Perceptron  
  1.1. Binary Classification Problem  
  1.2. Risk Function  
  1.3. Gradient Descent  
  1.4. Perceptron Algorithm
2. Nearest Neighbors  
  2.1. Nearest Neighbors Algorithm  
  2.2. Underfitting/Overfitting  
  2.3. Regularization
3. Data Extration  
  3.1. Binning/Bucketing  
  3.2. One Hot Encoding  
  3.3. Mathematical Transformations
4. Decision Trees  
  4.1. Overview  
  4.2. Information Gain/Entropy  
  4.3. Decision Tree Algorithm  
  4.4. Random Forest
5. Neural Networks  
  5.1. Multilayered Perceptrons  
  5.2. Activation Functions  
  5.3. Feedforward  
  5.4. Backpropogation  
  5.5. Neural Networks Algorithm  
  5.6. Potpourri for Neural Networks
6. Unsupervised Learning  
  6.1. K-means clustering  
  6.2 Hierarchical Clustering  
  6.3. Spectral Clustering  
  6.4. Dimensionality Reduction: PCA  
  6.5. Dimensionality Reduction: SVD

Contributions 
====

Author: @jpark96 <br />
Thank you ML@B members: @blchu, @raulpuric, and @philkuz!

Most of the material was taken from Berkeley's CS189 course. Many thanks to Professor Jonathan Shewchuck, who taught the course during the Spring 2016! Here's the reference to his notes (I VERY MUCH suggest this for a stronger mathematical understanding behind the algorithms): https://people.eecs.berkeley.edu/~jrs/papers/machlearn.pdf
