{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "## boilerplate that reduces the number of rows pandas outputs\n",
    "## makes display cleaner\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def strip(text):\n",
    "    try:\n",
    "        return text.strip()\n",
    "    except AttributeError:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('census.train', converters={'education' : strip,\n",
    "                                    'marital-status' : strip,\n",
    "                                    'occupation' : strip,\n",
    "                                    'race' : strip,\n",
    "                                    'sex' : strip,\n",
    "                                    'hours-per-week' : strip,\n",
    "                                    'prediction' : strip})\n",
    "\n",
    "test_data = pd.read_csv('census.test', converters={'education' : strip,\n",
    "                                    'marital-status' : strip,\n",
    "                                    'occupation' : strip,\n",
    "                                    'race' : strip,\n",
    "                                    'sex' : strip,\n",
    "                                    'hours-per-week' : strip,\n",
    "                                    'prediction' : strip})\n",
    "train_data = train_data.drop(['Unnamed: 0'], axis=1)\n",
    "test_data = test_data.drop(['Unnamed: 0'], axis=1)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "income_boundary = train_data['prediction']\n",
    "y = np.where(income_boundary == '<=50K',1,0)\n",
    "train_data = train_data.drop(['prediction'], axis=1)\n",
    "\n",
    "# We don't need these columns\n",
    "# to_drop = ['State','Area Code','Phone','Churn?']\n",
    "# churn_feat_space = churn_df.drop(to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the data\n",
    "Before working with a dataset, I spend a little bit of time trying to figure out the different aspects of the dataset. I'll glimpse through the table and get an idea of what types of variables are being represented, some of the possible values, etc. One of the first things I investigate is the number of unique values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# iteratie through the columns and count the unique values in each column\n",
    "for column in train_data:\n",
    "    print(column, len(np.unique(train_data[column])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives me a few insights about what techniques may be best for processing the data. For example, we now see that sex clearly has only two categories, therefore we'd definitely only want 1 feature to represent sex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with categorical Data\n",
    "Before we can even get close to framing this problem in a proper context, we need to deal with the categorical data. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "There are a number of techniques to approach this and each varies based on the type of data. \n",
    "\n",
    "The simplest of technique is to enumerate all possible categories and replace the categories with their numerical position. Fortunately, sklearn has the module just for us: [LabelEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)\n",
    "\n",
    "\n",
    "Let's start with the simple case - sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder as LE\n",
    "\n",
    "num_encoder = LE()\n",
    "encoded_train_data = train_data.copy()\n",
    "#to convert into numbers\n",
    "print('before encoding', np.unique(train_data['sex']))\n",
    "encoded_train_data['sex'] = num_encoder.fit_transform(train_data['sex'])\n",
    "print('after encoding', np.unique(encoded_train_data['sex']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course we will want to do the same for the other categorical variables. **Write a function that does this for a given list of column names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def le_categories(df, labels):\n",
    "    # test to make sure labels are in dataframe\n",
    "    assert set(labels).issubset(df.columns), \"Labels not in column names\"\n",
    "    encoded_df = df.copy()\n",
    "    ### STUDENT SOL START ###\n",
    "    for label in labels:\n",
    "        encoder = LE()\n",
    "        encoded_df[label] = encoder.fit_transform(encoded_df[label])\n",
    "    ### STUDENT SOL END ###\n",
    "    return encoded_df\n",
    "le_categories(train_data, ['sex', 'education', 'marital-status', 'occupation', 'race', ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's another way (and it's sometimes better!)\n",
    "Another technique to encode categorical data is called **One Hot Encoding**. Essentially, you're taking every possible category for a catgorical feature and making it it's own binary feature. \n",
    "\n",
    "One hot encoding can improve performance of a classifier by removing the notion of order the enumerated labels produced by labelencoding can include. Despite adding more features and thereby reducing performance, other techniques exist to offset this loss. Now let's try this out with marital status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset the data to undo the stuff we did in LE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#OHE EXAMPLE\n",
    "from sklearn.preprocessing import OneHotEncoder as OHE\n",
    "\n",
    "\n",
    "marstat_unique = np.unique(train_data['marital-status'])\n",
    "# sklearn One hot encoder only deals with numbers, so we run LE first \n",
    "encoded_train_data = le_categories(train_data, ['marital-status'])\n",
    "ohe_encoder = OHE()\n",
    "# enc.transform(['Male'])\n",
    "ohe_encoder.fit(encoded_train_data['marital-status'].reshape(-1, 1))\n",
    "# check number of values found\n",
    "ohe_encoder.n_values_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transform simply takes the columnar Gender data, then returns the OneHotEncoded matrix\n",
    "marstat_ohe = ohe_encoder.transform(encoded_train_data['marital-status'].reshape(-1, 1)).toarray()\n",
    "\n",
    "df = pd.DataFrame(marstat_ohe, dtype=np.int, columns=marstat_unique)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's join the two together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# encoded_train_data = encoded_train_data.drop(['marital-status'], axis=1)\n",
    "encoded_train_data = encoded_train_data.join(df)\n",
    "encoded_train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adopt the above example to work for a dataframe when given a list of column names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def ohe_catgories(df, labels):\n",
    "    assert set(labels).issubset(df.columns), \"Labels not in column names\"\n",
    "    encoded_train_data = train_data\n",
    "    ### STUDENT SOL START ###\n",
    "    \n",
    "    ### STUDENT SOL END ###\n",
    "ohe_categories(train_data, ['sex', 'education', 'marital-status', 'occupation', 'race'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you go! Now you have two excellent techniques that you can use to convert pesky categorical data into something your classifier will *love*. \n",
    "\n",
    "Choosing which method to use is up to you, but here are a few caveats to help make your decision easier:\n",
    "\n",
    "* Label encoding does bake in a notion of distance. This means that this method is best for categorical data with a notion of order.\n",
    "* If there is no notion of order, it's probably better to use one hot encoding as this better reflects the proper hamming distance (aka similarity) you'd expect for datapoints with such a label\n",
    "* One hot encoding comes with the trade off of increased dimensionality, which can quickly increase the amount of time your algorithm takes to train. This is especially prevalent with categorical data that has many categories - such as occupation in this dataset.\n",
    "\n",
    "## Moving On - Binning\n",
    "Now that we've explored categorical data, we can do some tricks to improve performance using continuous data as well. \n",
    "\n",
    "A popular and useful technique is called binning. The procedure involves breaking up a range of continuous numbers into equally sized chunks, then assigning each datapoint to their respective chunk. This significantly reduces the number of possible values that an algorithm needs to handle, oftentimes leading to significant accuracy increases. [This stackexchange answer](http://stats.stackexchange.com/questions/143806/why-binning-variables-in-predictive-analytics) runs through a few situations where binning may be beneficial.\n",
    "\n",
    "Let's try this out with the age column in our data. Pandas provides a simple method for binning data using the `cut` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEZCAYAAAC5AHPcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2a9e08b0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we'll start by analyzing the properties of the data \n",
    "age_feature = train_data['age']\n",
    "binned_column, bins = pd.cut(age_feature, bins=10, labels=False, retbins=True)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Age Histogram')\n",
    "plt.hist(age_feature, bins=bins) # you can switch this out with np.histogram, but it won't plot that way\n",
    "plt.show()   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, after playing around with the data, we can use pandas `cut` function to do this for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data['age_binned'] = binned_column\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
